---
title: "Significance Bands for Local Projetsions in R"
author: "Itamar Caspi"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    highlight: haddock
    keep_md: no
    theme: journal
    toc: yes
    toc_depth: 4
    toc_float: yes
abstract: This note aims to replicate the main finding presented in the paper "Significance Bands for Local Projections" by [Inoue, Jordà, and Kuersteiner (2023)](https://arxiv.org/abs/2306.03073). The original paper outlines the importance of using significance bands instead of traditional confidence bands for evaluating the dynamic impact of a treatment on an outcome variable via local projections. In particular, the note employs the R programming language to implement these methods, providing a detailed, step-by-step guide for researchers interested in applying them in their own analyses.
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  eval    = TRUE,
  echo    = TRUE,
  warning = FALSE,
  message = FALSE
)
```

## Introduction

[Inoue, Jordà, and Kuersteiner (2023)](https://arxiv.org/abs/2306.03073) propose employing significance bands with confidence bands to enhance impulse response function visualization. This approach allows for a more nuanced interpretation of statistical estimates. Confidence bands provide information on the uncertainty of each impulse response coefficient. In contrast, significance bands are better suited for visually assessing the null hypothesis, which posits that the entire impulse response is zero.

Standard statistical software and the Lagrange multiplier principle make constructing significance bands straightforward under the null hypothesis. This ease of construction is a noteworthy advantage. The bands' calculations do not depend on the impulse response horizon, and the paper provides approximate formulas. The authors also discuss bootstrap methods as a less assumption-reliant approach.

Monte Carlo simulations show that the proposed significance bands outperform traditional confidence bands. The simulations reveal that these bands have favorable size and power properties compared to solely considering whether confidence bands include zero. Thus, the authors argue that significance bands should be a standard graphical representation for impulse response functions.

In this paper, I replicate key findings from Inoue, Jordà, and Kuersteiner's study. Specifically, I focus on estimating local projections (LPs) for the Romer and Romer monetary policy shock. I then test these estimates using the significance bands method.

## Load packages
Start by loading the necessary packages
```{r}
library(tidyverse) # for data processing and plotting
library(broom)     # for tidying regression output
library(haven)     # for reading Stata .dta files
library(dynlm)     # for running dynamic regressions with leads and lags
library(sandwich)  # for Newey-West standard errors
library(lmtest)    # for coefficient tests
library(car)       # for linear hypothesis tests
```

## Basic setup

Parameters
```{r}
H     <- 17    # IRF horizon
pval  <- 0.05  # p-value
lags  <- 6     # lags to be used in LP regressions
nwlag <- H     # lags to be used in Newey-West
block <- H     # bootstrap block size
```

Sample
```{r}
smpl_start <- ymd("1985-01-01")
smpl_end   <- ymd("2007-12-31")
```

## Data

Load the `.dta` file
```{r}
df_raw <- read_dta("data/aggregatedata_final.dta")
```

Some preprocessing
```{r}
df <- df_raw %>%
  mutate(
    date   = observation_date,
    dlcpi  = 100 * dlcpi, # scale to work in percent
    lcpi   = 100 * lcpi   # scale to work in percent
  ) %>% 
  select(date, lcpi, rr_shock, dlcpi, dlrgdp, dstir) %>% 
  rename(
    y = lcpi,      # response 
    z = rr_shock   # instrument
  ) %>% 
  filter(between(date, smpl_start, smpl_end))

df_fwd <- df %>% 
  bind_cols(
    map_dfc(0:17, ~ df %>%
             transmute(!!paste0("ldy", .x) := lead(y, .x) - lag(y, 1)))
  )
```

## Orthogonalization

Define the control variables
```{r}
formula_x = "1 + L(dlrgdp, 1:lags) + L(dlcpi, 1:lags) + L(dstir, 1:lags)"
```

Orthogonalize $z_t$ w.r.t. controls
```{r}
formula_z <- paste0("z ~ ", formula_x) %>% as.formula()

model_z <- dynlm(formula_z, data = df_fwd %>% ts())

df_r_z <- model_z$residuals %>% 
  as_tibble() %>% 
  rename(r_z = 1)
```

Orthogonalize $y_{t+h}$ w.r.t. controls
```{r}
mat_r_y <- matrix(NA, length(df_r_z$r_z), H+1)

for (i in 0:H) {
  
  formula_y <- paste0("ldy", i, "~ ", formula_x) %>%  as.formula()
  model_y   <- dynlm(formula_y, data = df_fwd %>% ts())
  
  if (i == 0) {
    mat_r_y[ , i+1] <- model_y$residuals %>% as.vector()
  } else{
    mat_r_y[ , i+1] <- c(model_y$residuals %>% as.vector(), rep(NA, i))
  }

}

df_r_y <- mat_r_y %>% 
  as_tibble()

colnames(df_r_y) <- paste0("r_fy", 0:H)
```


Join the orthogonalized $y_{t_h}$ and $z_{t+h}$
```{r}
df_r_yz <- df_r_y %>% 
  bind_cols(df_r_z) %>% 
  mutate(date = 1:n()) 
```


## Local projections

Run the local projection procedure using the orthogonalized series
```{r}
mat_lp <- matrix(data = NA, ncol = 7, nrow = H+1)  # matrix to store estimation results

for (i in 0:H) {
  
  formula_r_y <- paste0("r_fy", i, " ~ r_z -1") %>% as.formula()
  lp_fit      <- dynlm(formula_r_y, data = df_r_yz %>% ts())
  
  nw_se     <- sqrt(diag(NeweyWest(lp_fit, lag = i)))
  n         <- length(lp_fit$residuals)
  nw_se_adj <- nw_se * sqrt((n - 1) / (n - 20))

  beta_i      <- lp_fit$coefficients["r_z"]
  se_beta_i   <-  nw_se_adj["r_z"]
  
  mat_lp[i+1, 1] <- i
  mat_lp[i+1, 2] <- beta_i
  mat_lp[i+1, 3] <- se_beta_i
  mat_lp[i+1, 4] <- beta_i + 1 * se_beta_i
  mat_lp[i+1, 5] <- beta_i - 1 * se_beta_i
  mat_lp[i+1, 6] <- beta_i + 2 * se_beta_i
  mat_lp[i+1, 7] <- beta_i - 2 * se_beta_i

}

df_lp <- mat_lp %>% 
  as_tibble()

colnames(df_lp) <- 
  c("horizon", "mid", "se", "up1sd", "down1sd", "up2sd", "down2sd")
```

plot LP and confidence bands
```{r}
df_lp %>% 
  ggplot(aes(x = horizon)) +
  geom_line(aes(y = mid), color = 'darkgreen', size = 1.5) +
  geom_ribbon(aes(ymin = down1sd, ymax = up1sd),
              fill = "darkgreen", linetype = 0, alpha = 0.2) +
  geom_ribbon(aes(ymin = down2sd, ymax = up2sd),
              fill = "darkgreen", linetype = 0, alpha = 0.1) +
  scale_x_continuous(expand = c(0,0), breaks = seq(0, H, 5)) +
  scale_y_continuous(expand = c(0,0), limits = c(-6, 2)) +
  labs(
    x = "Quearter",
    y = "Percent",
    title = "Cumulative response of the CPI in percent to a Romer monetary shock",
  ) +
  geom_hline(aes(yintercept = 0)) +
  theme_light(12, base_family = "Palatino Linotype") +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )
```



## Significance bands

### Significance bands using asymptotic approximation:

1. Calculate the sample average of the product (the orthogonalized) $s_t z_t$. Call this $\hat{\gamma}_{s z}$.
2. Construct the auxiliary variable $\eta_t=y_t z_t$ and regress $\eta_t$ on a constant. The Newey-West estimate of the standard error of the intercept coefficient is an estimate of $s_{\hat{\eta}}$.
3. An estimate of $\sigma / \sqrt{T-h}$, call it $\hat{s}_{\beta_h}$, is therefore:
$$
\hat{s}_{\beta_h}=\frac{\hat{s}_\eta}{\hat{\gamma}_{s z}}
$$
4. Construct the significance bands as:
$$
\left[\zeta_{\alpha / 2 H} \hat{\mathrm{s}}_{\beta_h}, \zeta_{1-\alpha / 2 H} \hat{\mathrm{s}}_{\beta_h}\right]
$$

```{r}
w         <- df_r_yz$r_z^2
mw        <- mean(w)
eta       <- df_r_yz$r_fy0 * df_r_yz$r_z^2
model_eta <- lm(eta ~ 1)

nw_se_eta <- sqrt(diag(NeweyWest(model_eta, lag = nwlag)))
seta      <- nw_se_eta["(Intercept)"]
sbeta     <- seta/mw

bju <- qnorm(1 - (pval / (2 * (H + 1)))) * sbeta
bjd <- -bju
```

### Significance bands using the Wold-Block Bootstrap:

1. Calculate the sample average of $s_t z_t$. Call this $\hat{\gamma}_{s z}$.
2. Construct the auxiliary variable $\eta_t=y_t z_t$ and regress $\eta_t$ on a constant. The Wild Block bootstrap estimate of the standard error of the intercept coefficient is an estimate of $s_{\hat{\eta}}$.
3. An estimate of $\sigma / \sqrt{T-h}$, call it $\hat{s}_{\beta_h}^b$, is therefore:
$$
\hat{s}_{\beta_h}^b=\frac{\hat{s}_{\eta \eta}^b}{\hat{\gamma}_{s z}}
$$
4. Construct the significance bands as:
$$
\left[\zeta_{\alpha / 2 H} \hat{s}_{\beta_{h^{\prime}}}^b \zeta_{1-\alpha / 2 H} \hat{s}_{\beta_h}^b\right]
$$


```{r}
set.seed(12345)   # for replication

n         <- length(df_r_yz$r_fy0)
block_id  <- floor((1:n + block - 1) / block)
model_eta <- lm(eta ~ 1)
nw_se_eta <- sqrt(diag(vcovBS(model_eta, cluster = block_id, R = 1000)))
seta      <- nw_se_eta["(Intercept)"]
sbeta     <- seta/mw

bootju <- qnorm(1 - (pval / (2 * (H + 1)))) * sbeta
bootjd <- -bootju
```

Join significance bands estimation results
```{r}
df_sb <- tibble(
  bju    = rep(bju, H+1),
  bjd    = rep(bjd, H+1),
  bootju = rep(bootju, H+1),
  bootjd = rep(bootjd, H+1)
)
```

The following graph illustrates the impulse response of 100 times the logarithm of the Consumer Price Index (CPI) following a Romer and Romer (2004) monetary olicy shock (extended by Wieland and Yang, 2020.) The model includes four lagged variables for CPI inflation, GDP growth, and a one-year Treasury Bill rate. The data sample covers the period from the first quarter of 1985 to the fourth quarter of 2007. Confidence bands at the 95% significance level are displayed; classical NW bands are shown in dashed blue and bootstrap bands in dashed red. Dark and light shaded areas indicate bands corresponding to one and two standard errors, respectively. For further details, refer to [Inoue, Jordà, and Kuersteiner (2023.)](https://arxiv.org/abs/2306.03073)
```{r}
df_lp %>% 
  bind_cols(df_sb) %>% 
  ggplot(aes(x = horizon)) +
  geom_line(aes(y = mid), color = 'darkgreen', size = 1.5) +
  geom_line(aes(y = bju), color = "red", linetype = 2, size = 1) +
  geom_line(aes(y = bjd), color = "red", linetype = 2, size = 1) +
  geom_line(aes(y = bootju), color = "blue", linetype = 2, size = 1) +
  geom_line(aes(y = bootjd), color = "blue", linetype = 2, size = 1) +
  geom_ribbon(aes(ymin = down1sd, ymax = up1sd),
              fill = "darkgreen", linetype = 0, alpha = 0.2) +
  geom_ribbon(aes(ymin = down2sd, ymax = up2sd),
              fill = "darkgreen", linetype = 0, alpha = 0.1) +
  scale_x_continuous(expand = c(0,0), breaks = seq(0, H, 5)) +
  scale_y_continuous(expand = c(0,0), limits = c(-6, 2)) +
  labs(
    x = "Quearter",
    y = "Percent",
    title = "Cumulative response of the CPI in percent to a Romer monetary shock",
  ) +
  geom_hline(aes(yintercept = 0)) +
  theme_light(12, base_family = "Palatino Linotype") +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )
```


## Stacked LPs

Transform the data to long format
```{r}
df_r_yz_long <- df_r_yz %>%
  pivot_longer(-c(date, r_z), names_to = "horizon", values_to = "r_fy") %>%
  mutate(
    horizon = as.factor(gsub("^r_fy", "", horizon))
  ) %>% 
  select(date, horizon, r_fy, r_z)
```

Estimate the stacked data as a panel
```{r}
library(plm)  # to estimate panel data models

plm_model <- plm(r_fy ~ factor(horizon):r_z, data = df_r_yz_long, index = c("horizon", "date"), model = "within")
```

Perform a joint hypothesis test
```{r}
hypothesis <- sapply(0:H, function(i) paste0("factor(horizon)", i, ":r_z = 0"))

linearHypothesis(plm_model, hypothesis, vcov. = function(x) vcovSCC(x, maxlag=nwlag))
```

